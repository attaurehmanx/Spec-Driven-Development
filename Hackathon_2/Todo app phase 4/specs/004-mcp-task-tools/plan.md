# Implementation Plan: MCP Task Tools

**Branch**: `004-mcp-task-tools` | **Date**: 2026-01-29 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/004-mcp-task-tools/spec.md`

## Summary

Implement an MCP (Model Context Protocol) server that exposes 5 task management tools to AI agents, enabling conversational task management. The MCP server will be a standalone module within the backend that shares database connections and models with the existing FastAPI application. Tools will support full CRUD operations (create, read, update, delete, complete) with user isolation and comprehensive validation.

**Technical Approach**: Use the official Anthropic MCP Python SDK with async/await patterns, integrate with existing SQLModel database layer via async sessions, implement tools as decorated async functions with Pydantic validation, and maintain strict user isolation at the query level.

## Technical Context

**Language/Version**: Python 3.10+
**Primary Dependencies**:
- MCP Python SDK (`mcp[cli]` v1.10.1) - Official Anthropic MCP implementation
- asyncpg - Async PostgreSQL driver for async database operations
- SQLModel - Existing ORM (shared with FastAPI)
- Pydantic - Input validation (built into MCP SDK)
- pytest, pytest-asyncio - Testing framework

**Storage**: PostgreSQL (Neon Serverless) - Shared with existing FastAPI backend
**Testing**: pytest with pytest-asyncio for async test support, MCP Inspector for manual testing
**Target Platform**: Linux server (same as FastAPI backend)
**Project Type**: Web application backend extension (MCP server module)
**Performance Goals**:
- Tool response time < 2 seconds for 1000+ tasks
- Support 10+ concurrent tool calls
- Database query time < 500ms

**Constraints**:
- Must share database connection pool with FastAPI
- Must maintain backward compatibility with existing Task and User models
- User isolation enforced at every operation
- No breaking changes to existing API

**Scale/Scope**:
- 5 tools (add_task, list_tasks, complete_task, update_task, delete_task)
- Support 1000+ tasks per user
- Support 100+ concurrent users
- Single MCP server instance (can scale horizontally if needed)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Principle I: Spec-first development ✅ PASS
- Specification created and approved before planning
- All requirements documented in spec.md
- User stories prioritized and independently testable

### Principle II: Single responsibility per spec ✅ PASS
- Feature focused solely on MCP task tools
- Does not include AI agent implementation
- Does not include frontend changes
- Clear boundary: tool interface only

### Principle III: Explicit contracts ✅ PASS
- All 5 tools have detailed contracts in contracts/ directory
- Input/output schemas defined in data-model.md
- Error responses documented
- Test cases specified

### Principle IV: Security by default ✅ PASS
- User isolation enforced at query level
- Ownership verification before modifications
- Input validation on all parameters
- No cross-user data access possible
- SQL injection prevention via ORM

### Principle V: Determinism ✅ PASS
- All tools have predictable behavior
- Same inputs produce same outputs
- Error handling is consistent
- No hidden state or side effects

### Principle VI: Agentic discipline ✅ PASS
- Research completed before design (research.md)
- Design artifacts created (data-model.md, contracts/, quickstart.md)
- Implementation plan follows template structure
- Tasks will be generated after plan approval

### Principle VII: Stateless AI interactions ✅ PASS
- Each tool call is independent
- No session state maintained
- User context passed explicitly in every call
- Tools can be called in any order

### Principle VIII: Conversation persistence ⚠️ NOT APPLICABLE
- This feature does not handle conversation persistence
- Conversation persistence is handled by feature 003-chat-database-schema

### Principle IX: User data isolation in AI context ✅ PASS
- Every tool requires user_id parameter
- All queries filter by user_id
- Ownership verified before modifications
- No shared data between users

**Overall Status**: ✅ ALL APPLICABLE PRINCIPLES PASS

## Project Structure

### Documentation (this feature)

```text
specs/004-mcp-task-tools/
├── spec.md              # Feature specification (completed)
├── plan.md              # This file (in progress)
├── research.md          # Technical research and decisions (completed)
├── data-model.md        # Tool input/output schemas (completed)
├── quickstart.md        # Setup and testing guide (completed)
├── contracts/           # Tool contracts (completed)
│   ├── add_task.md
│   ├── list_tasks.md
│   ├── complete_task.md
│   ├── update_task.md
│   └── delete_task.md
├── checklists/          # Quality validation (completed)
│   └── requirements.md
└── tasks.md             # Implementation tasks (to be generated by /sp.tasks)
```

### Source Code (repository root)

```text
backend/
├── mcp_server/                    # NEW: MCP server module
│   ├── __init__.py
│   ├── server.py                  # MCP server instance and lifecycle
│   ├── tools/
│   │   ├── __init__.py
│   │   └── task_tools.py          # 5 task management tools
│   ├── tests/
│   │   ├── __init__.py
│   │   ├── conftest.py            # Pytest fixtures
│   │   ├── test_task_tools_unit.py      # Unit tests (mocked DB)
│   │   └── test_task_tools_integration.py # Integration tests (real DB)
│   └── run_mcp.py                 # Entry point for MCP server
│
├── database/                      # MODIFIED: Add async support
│   ├── session.py                 # Add async_engine and get_async_session()
│   └── migrations.py              # No changes needed
│
├── models/                        # NO CHANGES: Reuse existing models
│   ├── task_models.py             # Task and User models (existing)
│   ├── conversation.py            # Existing from feature 003
│   └── message.py                 # Existing from feature 003
│
├── api/                           # NO CHANGES: Existing FastAPI routes
│   ├── tasks.py
│   ├── users.py
│   └── ...
│
├── config/                        # NO CHANGES: Existing configuration
│   └── settings.py
│
└── requirements.txt               # MODIFIED: Add mcp[cli], asyncpg, pytest-asyncio
```

**Structure Decision**:
- **Standalone MCP Module**: MCP server is a separate module within backend/ to maintain clear separation between AI agent interface (MCP) and web API interface (FastAPI)
- **Shared Resources**: Database session factory and models are shared between MCP server and FastAPI to avoid duplication
- **Independent Lifecycle**: MCP server can be started/stopped independently from FastAPI
- **Minimal Changes**: Only database/session.py needs modification to add async support; all other existing code remains unchanged

## Complexity Tracking

> **No violations to justify** - All constitution principles pass

## Implementation Strategy

### Phase 0: Research ✅ COMPLETED
- Researched MCP Python SDK options → Selected official Anthropic SDK
- Researched async patterns → Decided on async tools with AsyncSession
- Researched user context passing → Decided on explicit user_id parameters
- Researched error handling → Defined custom exception hierarchy
- Researched testing strategies → Multi-layer approach (unit, integration, manual)
- **Output**: research.md with all technical decisions documented

### Phase 1: Design & Contracts ✅ COMPLETED
- Created data-model.md with input/output schemas
- Created 5 tool contracts in contracts/ directory
- Created quickstart.md with setup and testing instructions
- **Output**: data-model.md, contracts/, quickstart.md

### Phase 2: Implementation (To be executed via /sp.tasks)

**2.1 Setup & Dependencies**
- Install MCP SDK and asyncpg
- Update requirements.txt
- Create MCP server directory structure

**2.2 Database Layer Enhancement**
- Modify database/session.py to add async engine
- Add get_async_session() function
- Test async database connection

**2.3 MCP Server Foundation**
- Create mcp_server/server.py with FastMCP instance
- Implement lifecycle management
- Create run_mcp.py entry point

**2.4 Tool Implementation (Priority Order)**
- P1: Implement add_task (MVP - create tasks)
- P2: Implement list_tasks (retrieve tasks)
- P3: Implement complete_task (mark complete)
- P4: Implement update_task (modify tasks)
- P5: Implement delete_task (remove tasks)

**2.5 Error Handling**
- Define custom exception classes
- Implement validation logic
- Add error logging

**2.6 Testing**
- Write unit tests with mocked database
- Write integration tests with real database
- Test with MCP Inspector
- Verify user isolation
- Performance testing

**2.7 Documentation**
- Add docstrings to all functions
- Create usage examples
- Document deployment process

### Phase 3: Validation & Deployment
- Run full test suite
- Verify all success criteria met
- Performance benchmarking
- Security audit
- Production deployment

## File Structure

### New Files to Create

| File Path | Purpose | Lines (Est.) |
|-----------|---------|--------------|
| `backend/mcp_server/__init__.py` | Module initialization | 5 |
| `backend/mcp_server/server.py` | MCP server instance | 30 |
| `backend/mcp_server/run_mcp.py` | Entry point script | 15 |
| `backend/mcp_server/tools/__init__.py` | Tools module init | 5 |
| `backend/mcp_server/tools/task_tools.py` | 5 task tools | 400 |
| `backend/mcp_server/tests/__init__.py` | Tests module init | 5 |
| `backend/mcp_server/tests/conftest.py` | Pytest fixtures | 50 |
| `backend/mcp_server/tests/test_task_tools_unit.py` | Unit tests | 200 |
| `backend/mcp_server/tests/test_task_tools_integration.py` | Integration tests | 150 |
| **Total** | | **~860 lines** |

### Files to Modify

| File Path | Changes | Impact |
|-----------|---------|--------|
| `backend/database/session.py` | Add async engine and session factory | +30 lines, LOW risk |
| `backend/requirements.txt` | Add mcp[cli], asyncpg, pytest-asyncio | +3 lines, LOW risk |

**Total Implementation**: ~860 new lines, ~33 modified lines

## Testing Strategy

### Unit Tests (Mocked Database)
**Location**: `backend/mcp_server/tests/test_task_tools_unit.py`

**Coverage**:
- All 5 tools with valid inputs
- All error paths (user not found, task not found, unauthorized access)
- Input validation (empty title, too long, invalid status)
- Edge cases (empty task list, already completed task)

**Approach**:
- Mock AsyncSession with AsyncMock
- Mock database queries and responses
- Fast execution (< 1 second for all unit tests)
- 100% code coverage target

### Integration Tests (Real Database)
**Location**: `backend/mcp_server/tests/test_task_tools_integration.py`

**Coverage**:
- Full task lifecycle (create → list → complete → update → delete)
- User isolation verification
- Database constraints (foreign keys, unique constraints)
- Performance benchmarks

**Approach**:
- Use test database or transaction rollback
- Create test users and tasks
- Verify database state after operations
- Clean up test data

### Manual Testing (MCP Inspector)
**Tool**: `npx @modelcontextprotocol/inspector`

**Coverage**:
- Tool discovery (verify all 5 tools appear)
- Interactive tool calls with various inputs
- Error message clarity
- Response format validation

**Approach**:
- Run MCP server in one terminal
- Run Inspector in another terminal
- Test each tool with valid and invalid inputs
- Verify AI-friendly error messages

### Performance Testing
**Benchmarks**:
- add_task: < 100ms
- list_tasks: < 500ms for 100 tasks, < 2s for 1000 tasks
- complete_task: < 100ms
- update_task: < 100ms
- delete_task: < 100ms

**Approach**:
- Create large datasets (1000+ tasks)
- Measure response times
- Verify performance targets met
- Identify bottlenecks if targets missed

### Security Testing
**Scenarios**:
- Cross-user access attempts (should fail)
- SQL injection attempts (should be prevented)
- Input validation bypass attempts (should fail)
- Ownership verification (should block unauthorized access)

**Approach**:
- Attempt to access other users' tasks
- Try malicious inputs
- Verify all security measures work
- Document security test results

## Deployment Strategy

### Development Environment
```bash
# Terminal 1: Run FastAPI backend
cd backend
uvicorn main:app --reload

# Terminal 2: Run MCP server
cd backend
python mcp_server/run_mcp.py
```

### Production Environment

**Option 1: Systemd Service (Linux)**
```ini
# /etc/systemd/system/mcp-task-tools.service
[Unit]
Description=MCP Task Tools Server
After=network.target postgresql.service

[Service]
Type=simple
User=www-data
WorkingDirectory=/var/www/backend
Environment="DATABASE_URL=postgresql://..."
ExecStart=/usr/bin/python3 mcp_server/run_mcp.py
Restart=always

[Install]
WantedBy=multi-user.target
```

**Option 2: Docker Container**
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY backend/ /app/
RUN pip install -r requirements.txt
CMD ["python", "mcp_server/run_mcp.py"]
```

**Option 3: Process Manager (PM2)**
```json
{
  "apps": [{
    "name": "mcp-task-tools",
    "script": "mcp_server/run_mcp.py",
    "interpreter": "python3",
    "cwd": "/var/www/backend",
    "env": {
      "DATABASE_URL": "postgresql://..."
    }
  }]
}
```

### Monitoring & Logging

**Logging Configuration**:
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/mcp-task-tools.log'),
        logging.StreamHandler()
    ]
)
```

**Metrics to Track**:
- Tool call counts by tool name
- Success/failure rates
- Response times (p50, p95, p99)
- Database query times
- Error rates by error type

## Risk Assessment

### Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Async/sync compatibility issues | Medium | Medium | Thorough testing, separate async engine |
| Database connection pool exhaustion | Low | High | Configure pool size, monitor connections |
| MCP SDK breaking changes | Low | Medium | Pin SDK version, test before upgrades |
| Performance degradation with large datasets | Medium | Medium | Implement pagination, optimize queries |
| User isolation bypass | Low | Critical | Comprehensive security testing, code review |

### Operational Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| MCP server crashes | Low | High | Process manager with auto-restart, monitoring |
| Database connection failures | Low | High | Connection pooling, retry logic, health checks |
| Memory leaks in long-running process | Low | Medium | Regular restarts, memory monitoring |
| Concurrent access conflicts | Low | Low | Database transactions, optimistic locking |

### Security Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Cross-user data access | Low | Critical | User isolation at query level, ownership checks |
| SQL injection | Very Low | Critical | ORM usage, parameterized queries |
| Input validation bypass | Low | Medium | Pydantic validation, custom validators |
| Unauthorized tool access | Low | High | User authentication required, user_id validation |

## Dependencies

### External Dependencies
- **MCP Python SDK**: Official Anthropic SDK for MCP server implementation
- **asyncpg**: Async PostgreSQL driver for database operations
- **SQLModel**: ORM for database models (existing)
- **Pydantic**: Data validation (built into MCP SDK)
- **pytest**: Testing framework (existing)
- **pytest-asyncio**: Async test support

### Internal Dependencies
- **Feature 001-task-api-persistence**: Requires Task and User models
- **Feature 002-auth-identity-boundary**: Requires user authentication context
- **Database**: Requires PostgreSQL database with existing schema

### Future Dependencies (Out of Scope)
- **AI Agent Service**: Will consume MCP tools (future feature)
- **Frontend Chat Interface**: Will trigger AI agent calls (future feature)

## Success Criteria Validation

### From Specification

| Criterion | Validation Method | Target |
|-----------|-------------------|--------|
| SC-001: 100% accuracy in user ownership | Security tests | 0 cross-user access incidents |
| SC-002: <2s retrieval for 1000 tasks | Performance tests | All queries < 2s |
| SC-003: 0% cross-user data leakage | Security audit | All queries filter by user_id |
| SC-004: 99.9% operation success rate | Integration tests | < 0.1% failure rate |
| SC-005: Clear error messages | Manual testing | AI can understand all errors |
| SC-006: 95% user success without docs | Usability testing | Tool signatures self-explanatory |
| SC-007: 0% data loss | Integration tests | All operations persist correctly |

### Validation Plan
1. **Unit Tests**: Verify all business logic works correctly
2. **Integration Tests**: Verify database operations work correctly
3. **Performance Tests**: Verify response time targets met
4. **Security Tests**: Verify user isolation and input validation
5. **Manual Tests**: Verify error messages are clear and helpful
6. **MCP Inspector**: Verify tools are discoverable and usable

## Next Steps

1. **Approve Plan**: Review and approve this implementation plan
2. **Generate Tasks**: Run `/sp.tasks` to create detailed task breakdown
3. **Implement**: Execute tasks in priority order (P1 → P2 → P3 → P4 → P5)
4. **Test**: Run full test suite after each phase
5. **Deploy**: Deploy to production after all tests pass
6. **Monitor**: Track metrics and errors in production

## Notes

- **Backward Compatibility**: No changes to existing FastAPI routes or models
- **Shared Resources**: Database connection pool shared between FastAPI and MCP server
- **Independent Deployment**: MCP server can be deployed separately from FastAPI
- **Scalability**: Can run multiple MCP server instances if needed
- **Future Enhancements**: Can add more tools without affecting existing ones
